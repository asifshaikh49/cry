{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.linalg import dft\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft, ifft, dct, idct\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython\n",
    "import time\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory='Baby cry'):\n",
    "  \n",
    "    subdirs = os.listdir(directory)\n",
    "    wavforms = []\n",
    "    labels = []\n",
    "    for dirc in subdirs:\n",
    "        filenames = os.listdir(directory+'/'+dirc)\n",
    "        for filename in filenames:\n",
    "            # Get wavform from each file \n",
    "            wav = wavfile.read(directory+'/'+dirc+'/'+filename)[1]\n",
    "                \n",
    "            # Store wavform and appropriate label\n",
    "            wavforms.append(wav)\n",
    "            labels.append(dirc)\n",
    "    \n",
    "    # Find the minimum wavform length.\n",
    "    lens = set()\n",
    "    for d in wavforms:\n",
    "        lens.add(len(d))\n",
    "    min_len = min(lens)\n",
    "    \n",
    "    # Cut the end off each wavform so they're the same lengths.\n",
    "    for i,wav in enumerate(wavforms):\n",
    "        wavforms[i] = wav[:min_len]\n",
    "        \n",
    "    return np.array(wavforms), np.array(labels)\n",
    "\n",
    "def cut_data(data, labels, n):\n",
    "   \n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    # Get number of possible subsamples from current samples\n",
    "    subs = data.shape[1]//n\n",
    "\n",
    "    # Cut each sample\n",
    "    for i, wav in enumerate(data):\n",
    "        # Get as many new samples from old sample as possible\n",
    "        for x in range(subs):\n",
    "            # Extract subsamples of length n\n",
    "            new_data.append(wav[x*n:(x+1)*n])\n",
    "            # Store corresponding label\n",
    "            new_labels.append(labels[i])\n",
    "            \n",
    "    return np.array(new_data), np.array(new_labels)\n",
    "\n",
    "\n",
    "\n",
    "def get_fft(data, rate=8000, sample_rate=100):\n",
    "  \n",
    "    freqs = []\n",
    "    freq_domain = np.arange(0, len(data[0])) * rate / len(data[0])\n",
    "    freq_domain = freq_domain[:len(freq_domain)//2]\n",
    "\n",
    "    for i, wav in enumerate(data):\n",
    "        # Get frequencies using Fourier Transform\n",
    "        f = np.abs(fft(wav))[:len(freq_domain)]\n",
    "        # Get real part of frequencies, normalize, and sample at the sample rate\n",
    "        tmp = (np.real(f) / max(np.real(f)))[::sample_rate]\n",
    "        freqs.append(list(tmp))\n",
    "    \n",
    "    return np.array(freqs), freq_domain[::sample_rate]\n",
    "\n",
    "def data_to_df(data, labels, freqs):\n",
    "    \n",
    "    # Data to df\n",
    "    df = pd.DataFrame(data,columns=freqs)\n",
    "    # Labels column\n",
    "    df['labels'] = labels\n",
    "    return df\n",
    "\n",
    "def labels_to_integers(labels):\n",
    "    \n",
    "    new_labels = np.zeros(labels.shape)\n",
    "    mapping = {}\n",
    "    \n",
    "    for idx, lab in enumerate(np.unique(labels)):\n",
    "        new_labels[labels==lab] = idx\n",
    "        mapping[idx] = lab\n",
    "    \n",
    "    return new_labels, mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA PREPARATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_data('baby cry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'belly_pain augmented',\n",
       " 'burping augmented',\n",
       " 'discomfort augmented',\n",
       " 'hungry',\n",
       " 'tired_augmented'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|# samples\t|avg len\t|avg min wvl\t|avg max wvl\t|abs min wvl\t|abs max wvl\t|label\n",
      "------------------------------------------------------------------------------------------------------\n",
      "|382\t\t|52160.00\t|-19543.69\t|20013.27\t|-32768.00\t|32767.00\t|hungry\n",
      "|72\t\t|52160.00\t|-14417.58\t|14879.79\t|-32768.00\t|32767.00\t|tired_augmented\n",
      "|81\t\t|52160.00\t|-16962.59\t|17576.43\t|-32768.00\t|32767.00\t|discomfort augmented\n",
      "|48\t\t|52160.00\t|-13504.48\t|12411.73\t|-32768.00\t|32767.00\t|belly_pain augmented\n",
      "|24\t\t|52160.00\t|-24876.50\t|25274.08\t|-32768.00\t|32767.00\t|burping augmented\n"
     ]
    }
   ],
   "source": [
    "print('|{0}\\t|{1}\\t|{2}\\t|{3}\\t|{4}\\t|{5}\\t|{6}'.format('# samples', 'avg len', \n",
    "                                                       'avg min wvl', 'avg max wvl', \n",
    "                                                       'abs min wvl', 'abs max wvl', 'label'))\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "for label in set(labels):\n",
    "    tmp = data[labels==label]\n",
    "    num_samples = len(tmp)\n",
    "    avg_len = sum(len(row) for row in tmp)/num_samples\n",
    "    avg_max_wvl = sum([max(row) for row in tmp])/num_samples\n",
    "    avg_min_wvl = sum([min(row) for row in tmp])/num_samples\n",
    "    abs_min_wvl = min([min(row) for row in tmp])\n",
    "    abs_max_wvl = max([max(row) for row in tmp])\n",
    "    print(u\"|{0}\\t\\t|{1:0.2f}\\t|{2:0.2f}\\t|{3:0.2f}\\t|{4:0.2f}\\t|{5:0.2f}\\t|{6}\".format(num_samples, avg_len, \n",
    "                                                                                  avg_min_wvl, avg_max_wvl, \n",
    "                                                                                  abs_min_wvl, abs_max_wvl,\n",
    "                                                                                  label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hungry_data = data[labels!='hungry']\n",
    "non_hungry_labels = labels[labels!='hungry']\n",
    "cut_data, cut_labels = cut_data(non_hungry_data,non_hungry_labels, 25000)\n",
    "#dup_data, dup_labels = duplicate_data(cut_data,cut_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hungry_data = data[labels=='hungry'][:140]\n",
    "hungry_labels = ['hungry']*140\n",
    "hungry_data = hungry_data[:,:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = np.vstack((hungry_data,cut_data))\n",
    "final_labels = np.hstack((hungry_labels, cut_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, f_domain = get_fft(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|# samples\t|avg len\t|avg min freq\t|avg max freq\t|abs min freq\t|abs max freq\t|label\n",
      "------------------------------------------------------------------------------------------------------\n",
      "|140\t\t|25000.00\t\t|-17063.59\t\t|17257.78\t\t|-32768.00\t\t|32767.00\t\t|hungry\n",
      "|144\t\t|25000.00\t\t|-11016.14\t\t|11404.10\t\t|-32768.00\t\t|32767.00\t\t|tired_augmented\n",
      "|162\t\t|25000.00\t\t|-14598.77\t\t|15190.67\t\t|-32768.00\t\t|32767.00\t\t|discomfort augmented\n",
      "|96\t\t|25000.00\t\t|-10876.91\t\t|10223.34\t\t|-32768.00\t\t|32767.00\t\t|belly_pain augmented\n",
      "|48\t\t|25000.00\t\t|-20265.56\t\t|20877.73\t\t|-32768.00\t\t|32767.00\t\t|burping augmented\n"
     ]
    }
   ],
   "source": [
    "print('|{0}\\t|{1}\\t|{2}\\t|{3}\\t|{4}\\t|{5}\\t|{6}'.format('# samples', 'avg len', \n",
    "                                                       'avg min freq', 'avg max freq', \n",
    "                                                       'abs min freq', 'abs max freq', 'label'))\n",
    "print('------------------------------------------------------------------------------------------------------')\n",
    "for label in set(final_labels):\n",
    "    tmp = final_data[final_labels==label]\n",
    "    num_samples = len(tmp)\n",
    "    avg_len = sum(len(row) for row in tmp)/num_samples\n",
    "    avg_max_wvl = sum([max(row) for row in tmp])/num_samples\n",
    "    avg_min_wvl = sum([min(row) for row in tmp])/num_samples\n",
    "    abs_min_wvl = min([min(row) for row in tmp])\n",
    "    abs_max_wvl = max([max(row) for row in tmp])\n",
    "    print(u\"|{0}\\t\\t|{1:0.2f}\\t\\t|{2:0.2f}\\t\\t|{3:0.2f}\\t\\t|{4:0.2f}\\t\\t|{5:0.2f}\\t\\t|{6}\".format(num_samples, avg_len, \n",
    "                                                                                  avg_min_wvl, avg_max_wvl, \n",
    "                                                                                  abs_min_wvl, abs_max_wvl,\n",
    "                                                                                  label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 25000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply MFCC + GMMHMM : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import os\n",
    "import librosa\n",
    "import gmmhmm\n",
    "import pickle # Will want to save models so we don't have to keep re-training them.\n",
    "from multiprocessing import Pool # train models faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_gmmhmm(n):\n",
    "  \n",
    "    np.random.seed(int.from_bytes(os.urandom(4), byteorder='little'))\n",
    "    \n",
    "    # create initial state distribution\n",
    "    startprob = np.random.rand(n)\n",
    "    startprob /= np.sum(startprob)\n",
    "    \n",
    "    # create transition matrix\n",
    "    transmat = np.random.rand(n,n)\n",
    "    transmat = (transmat.T/np.sum(transmat, axis=1)).T\n",
    "    \n",
    "    # return results\n",
    "    return startprob, transmat\n",
    "\n",
    "def make_new_model(mfcc):\n",
    "    \n",
    "    startprob, transmat = initialize_gmmhmm(5)\n",
    "    model = gmmhmm.GMMHMM(\n",
    "        n_components=5, \n",
    "        n_mix=3, # Could try varying this? \n",
    "        transmat=transmat, \n",
    "        startprob=startprob, \n",
    "        cvtype='diag'\n",
    "    )\n",
    "    model.covars_prior = 0.02 # Could try varying this?\n",
    "    model.fit(mfcc, init_params='mc', var=0.1) # Could try varying this?\n",
    "    return model\n",
    "\n",
    "def generate_models(X, y, num_compare=6):\n",
    "    \n",
    "    for model_num in np.unique(y):\n",
    "        \n",
    "        print(f'Generating GMM HMM for label {model_num}...', end='')\n",
    "        \n",
    "        # Generate several models with different initializations.     \n",
    "        multiple_models = []\n",
    "        for _ in range(num_compare):\n",
    "            failed = True\n",
    "            while failed:\n",
    "                try:\n",
    "                    new_model = make_new_model(X[y == model_num])\n",
    "                    multiple_models.append(new_model)\n",
    "                    failed = False\n",
    "                except ValueError as err:\n",
    "                    print('..failed, try again..',end='')\n",
    "        \n",
    "        # Choose the 'best' model (based on log-probability).\n",
    "        model = multiple_models[np.argmax([x.logprob for x in multiple_models])]\n",
    "        \n",
    "        print('...saving.')\n",
    "        save_gmmhmm_model(model, f'model{model_num}', filepath='gmmhmm_models')\n",
    "\n",
    "def save_gmmhmm_model(model, filename, filepath='.'):\n",
    "   \n",
    "    with open(f'{filepath}/{filename}.pickle', 'wb') as fh:\n",
    "        pickle.dump(model, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def get_gmmhmm_models(y, filepath='gmmhmm_models'):\n",
    "   \n",
    "    models = []\n",
    "    for n in np.unique(y):\n",
    "        with open(f'{filepath}/model{n}.pickle', 'rb') as model_file:\n",
    "            models.append(pickle.load(model_file))\n",
    "    \n",
    "    return models\n",
    "\n",
    "def gmmhmm_predict(models, X):\n",
    "  \n",
    "    most_likely = np.array(\n",
    "        [np.argmax([m.score(cry) for m in models]) for cry in X]\n",
    "    )\n",
    "    return most_likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 49, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the Mel-Frequency Cepstrum Coefficients (MFCCs)\n",
    "Xmfcc = []\n",
    "for x in final_data:\n",
    "    Xmfcc.append(librosa.feature.mfcc(y=x.astype(float), sr=8000, n_mfcc=12))\n",
    "Xmfcc = np.array(Xmfcc)\n",
    "Xmfcc = np.swapaxes(Xmfcc, 1, 2)\n",
    "Xmfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_labels = labels_to_integers(final_labels)[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_data, int_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmfcc_train, Xmfcc_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xmfcc, final_data, int_labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GMM HMM for label 0.0......saving.\n",
      "Generating GMM HMM for label 1.0.....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again.....saving.\n",
      "Generating GMM HMM for label 2.0.....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again.....saving.\n",
      "Generating GMM HMM for label 3.0......saving.\n",
      "Generating GMM HMM for label 4.0.....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again....failed, try again.....saving.\n"
     ]
    }
   ],
   "source": [
    "generate_models(np.array(Xmfcc_train), y_train, num_compare=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmmhmm_models = get_gmmhmm_models(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, 0, 0, 3, 2, 0, 3, 3, 3, 1, 2, 0, 2, 2, 0, 2, 4, 4, 3, 3,\n",
       "       1, 4, 0, 3, 3, 3, 1, 2, 3, 0, 0, 1, 1, 0, 3, 0, 4, 4, 1, 0, 0, 0,\n",
       "       2, 1, 3, 3, 3, 1, 0, 2, 3, 4, 0, 2, 3, 3, 2, 0, 2, 2, 3, 0, 3, 2,\n",
       "       2, 2, 1, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 1, 0, 1, 3, 3, 1, 3, 3, 4,\n",
       "       0, 3, 0, 3, 2, 3, 0, 1, 4, 2, 1, 0, 0, 1, 3, 2, 3, 3, 1, 0, 0, 1,\n",
       "       2, 2, 1, 2, 3, 2, 4, 0, 3, 0, 2, 0, 1, 2, 4, 3, 2, 3, 3, 3, 1, 1,\n",
       "       3, 3, 0, 3, 4, 1, 2, 3, 3, 3, 0, 2, 2, 2, 4, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gmmhmm_predict(gmmhmm_models, Xmfcc_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it seemed very likely that our best option would be neural networks: even though GMMHMM\n",
    "classifiers were often used for automatic speech recognition in the past, neural networks have since\n",
    "replaced them as the industry standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
